{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62be1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57ce584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/15 21:41:12 WARN Utils: Your hostname, outline resolves to a loopback address: 127.0.1.1; using 10.129.0.21 instead (on interface eth0)\n",
      "23/04/15 21:41:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/15 21:41:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://outline.ru-central1.internal:7077\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6fe3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.129.0.21:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://outline.ru-central1.internal:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa5bdec8d60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6b2819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "_columns=[\"Id\",\"Name\",\"CountsOfReview\"]\n",
    "dfs = [spark.read\n",
    "       .option(\"header\", True)\n",
    "       .option(\"quote\", \"\\\"\")\n",
    "       .option(\"escape\", \"\\\"\")\n",
    "       .option(\"multiLine\", True)\n",
    "       #.schema(customSchema)\n",
    "       .option(\"inferSchema\", True) \n",
    "       .csv('data/'+file)\n",
    "       #.select(_columns)\n",
    "       for file in os.listdir(r'data') if file.startswith(\"book\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da857e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457d718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    merged_df = merged_df.unionByName(dfs[i], allowMissingColumns=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a71d780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Id: int, Name: string, Authors: string, ISBN: string, Rating: double, PublishYear: int, PublishMonth: int, PublishDay: int, Publisher: string, RatingDist5: string, RatingDist4: string, RatingDist3: string, RatingDist2: string, RatingDist1: string, RatingDistTotal: string, CountsOfReview: int, Language: string, pagesNumber: int, Description: string, Count of text reviews: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a28e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merged_df.repartition(1).write.parquet('data/parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01fa18cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merged_df.repartition(1).write.csv('data/merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59a08d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df_csv=spark.read.csv(\"data/merged/part-00000-26cb797a-491c-4cba-a52b-4ae54e03765f-c000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9622ec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df=spark.read.parquet(\"data/parquet/part-00000-e8c84c05-9b92-4623-bbf1-4424f9b5e8b9-c000.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2949ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+----------+------+-----------+------------+----------+--------------------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+--------+-----------+--------------------+---------------------+\n",
      "|     Id|                Name|         Authors|      ISBN|Rating|PublishYear|PublishMonth|PublishDay|           Publisher|RatingDist5|RatingDist4|RatingDist3|RatingDist2|RatingDist1|RatingDistTotal|CountsOfReview|Language|pagesNumber|         Description|Count of text reviews|\n",
      "+-------+--------------------+----------------+----------+------+-----------+------------+----------+--------------------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+--------+-----------+--------------------+---------------------+\n",
      "|1700000|Montmorency On Th...|  Eleanor Updale|0439606764|  3.89|       2005|           1|         4|       Orchard Books|      5:346|      4:501|      3:313|       2:64|       1:13|     total:1237|             9|    null|        368|Montmorency, the ...|                 null|\n",
      "|1700004|The Sweetest Vale...|  Jane E. Gerver|0439283086|  3.83|       2003|           1|         1|           Cartwheel|        5:9|        4:4|       3:10|        2:0|        1:1|       total:24|             3|    null|         32|A classroom proje...|                 null|\n",
      "|1700007|Institutional Str...|George M. Thomas|0803928920|   0.0|       1987|           1|         7|Sage Publications...|        5:0|        4:0|        3:0|        2:0|        1:0|        total:0|             0|    null|        372|The authors show ...|                 null|\n",
      "|1700013|    Gal: A True Life|   Ruthie Bolton|0151001049|  4.05|       1994|          23|         5|Houghton Mifflin ...|      5:417|      4:342|      3:196|       2:54|       1:19|     total:1028|            12|     eng|        275|Ruthie Mae Bolton...|                 null|\n",
      "|1700014|Apollon à Wall St...|  Maurice Rheims|202019113X|   3.0|       1992|          30|         9|               Seuil|        5:0|        4:0|        3:1|        2:0|        1:0|        total:1|             0|     fre|        832|                null|                 null|\n",
      "+-------+--------------------+----------------+----------+------+-----------+------------+----------+--------------------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+--------+-----------+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e55d7a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+\n",
      "|     Id|                Name|CountsOfReview|\n",
      "+-------+--------------------+--------------+\n",
      "|2767052|The Hunger Games ...|        154447|\n",
      "|  41865|Twilight (Twiligh...|         94850|\n",
      "|  19063|      The Book Thief|         87685|\n",
      "|4667024|            The Help|         76040|\n",
      "|      3|Harry Potter and ...|         75911|\n",
      "|   3636|The Giver (The Gi...|         57034|\n",
      "|  43641| Water for Elephants|         52918|\n",
      "|2429135|The Girl with the...|         52225|\n",
      "| 136251|Harry Potter and ...|         52088|\n",
      "|  28187|The Lightning Thi...|         48630|\n",
      "+-------+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 57:================================================>         (5 + 1) / 6]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\"Id\",\"Name\",\"CountsOfReview\") \\\n",
    "  .orderBy(df.CountsOfReview.desc()) \\\n",
    "  .show(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3883f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           Publisher|  avg(pagesNumber)|\n",
      "+--------------------+------------------+\n",
      "|Crafty Secrets Pu...|         1807321.6|\n",
      "|    Sacred-texts.com|          500000.0|\n",
      "|Department of Rus...| 322128.5714285714|\n",
      "|Logos Research Sy...|          100000.0|\n",
      "|Encyclopedia Brit...|           32642.0|\n",
      "|Progressive Manag...|        19106.3625|\n",
      "|Still Waters Revi...|10080.142857142857|\n",
      "|P. Shalom Publica...|            8539.0|\n",
      "|Hendrickson Publi...|            6448.0|\n",
      "|            IEEE/EMB|            6000.0|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 60:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "top_publishers = df.groupBy(\"Publisher\") \\\n",
    "                  .mean(\"pagesNumber\") \\\n",
    "                  .orderBy(desc(\"avg(pagesNumber)\")) \\\n",
    "                  .limit(10)\n",
    "\n",
    "top_publishers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e970ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|PublishYear| count|\n",
      "+-----------+------+\n",
      "|       2007|129507|\n",
      "|       2006|122374|\n",
      "|       2005|117639|\n",
      "|       2004|105733|\n",
      "|       2003|104345|\n",
      "|       2002| 95537|\n",
      "|       2001| 88228|\n",
      "|       2000| 87290|\n",
      "|       2008| 80265|\n",
      "|       1999| 80155|\n",
      "+-----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 62:================================================>         (5 + 1) / 6]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_years = df.groupBy(\"PublishYear\") \\\n",
    "              .count() \\\n",
    "              .orderBy(desc(\"count\")) \\\n",
    "              .limit(10)\n",
    "\n",
    "top_years.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4356798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "df2 = df.alias('df2')\n",
    "id(df2) == id(df)  # False\n",
    "cols_to_update = [\"RatingDist1\", \"RatingDist2\", \"RatingDist3\", \"RatingDist4\", \"RatingDist5\", \"RatingDistTotal\"]\n",
    "\n",
    "for col in cols_to_update:\n",
    "    df2 = df2.withColumn(col, split(df2[col], \":\").getItem(1).cast(\"integer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5160866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                Name|         RatingStd|\n",
      "+--------------------+------------------+\n",
      "|Scientology: The ...|1.6768965920829089|\n",
      "|Scientology: The ...|1.6754156681545784|\n",
      "|Para Entrenar a u...|1.6599055615998013|\n",
      "| To Train Up a Child|1.6595374499170727|\n",
      "|Para Entrenar a u...|1.6594896798570395|\n",
      "|The Bluebook: A U...|1.5883197973323213|\n",
      "|The Bluebook: A U...|1.5883197973323213|\n",
      "|Dianetics: The Mo...|1.5621133225369277|\n",
      "|Dianetics: The Mo...|1.5608985177269006|\n",
      "|Dianetica: La Cie...| 1.560359470866146|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 65:================================================>         (5 + 1) / 6]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "filtered_df = df2.filter(col(\"RatingDistTotal\") > 500)\n",
    "\n",
    "std_df = filtered_df.withColumn(\"RatingStd\", (((5 - col(\"Rating\"))**2 * col(\"RatingDist5\") + (4 - col(\"Rating\"))**2 * col(\"RatingDist4\") + (3 - col(\"Rating\"))**2 * col(\"RatingDist3\") + (2 - col(\"Rating\"))**2 * col(\"RatingDist2\") + (1 - col(\"Rating\"))**2 * col(\"RatingDist1\"))/col(\"RatingDistTotal\"))**0.5)\n",
    "top10_df = std_df.sort(col(\"RatingStd\").desc()).limit(10)\n",
    "top10_df.select(\"Name\", \"RatingStd\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21ab5e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 best year average rating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 133:===============================================>         (5 + 1) / 6]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+---------+\n",
      "|PublishYear|     AverageRating|BookCount|\n",
      "+-----------+------------------+---------+\n",
      "|       1983| 3.968961384820239|     1502|\n",
      "|       1992|3.9631608884073657|     3692|\n",
      "|       1986| 3.960931417979612|     2158|\n",
      "|       1988| 3.960540768905788|     2367|\n",
      "|       1989|3.9575137039937367|     2554|\n",
      "|       1990|  3.95593340060545|     2973|\n",
      "|       1991| 3.954548769371009|     3291|\n",
      "|       1993|3.9543992796501155|     3887|\n",
      "|       1994|3.9542364187456305|     4289|\n",
      "|       1984|3.9533858267716537|     1905|\n",
      "+-----------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "top-10 worst year average rating\n",
      "+-----------+------------------+---------+\n",
      "|PublishYear|     AverageRating|BookCount|\n",
      "+-----------+------------------+---------+\n",
      "|       2008|3.9069505767321124|    13091|\n",
      "|       2007|3.9145397965290276|    16710|\n",
      "|       2009|3.9187002775208137|     2162|\n",
      "|       2006|3.9253816189092805|    15146|\n",
      "|       2004|3.9326649958228876|    11970|\n",
      "|       2005|3.9356867523260965|    13542|\n",
      "|       2003| 3.938638139365856|    11007|\n",
      "|       2002|3.9390600059119087|    10149|\n",
      "|       1999| 3.940360547036886|     7239|\n",
      "|       1987| 3.942828242760811|     2521|\n",
      "+-----------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 136:===============================================>         (5 + 1) / 6]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "filtered_df = df2.filter((col(\"PublishYear\") >= 1000) & \n",
    "                         (col(\"PublishYear\") <= 2022) & \n",
    "                         (col(\"RatingDistTotal\") > 500))\n",
    "grouped_df = filtered_df.groupBy(\"PublishYear\")\\\n",
    "                        .agg(avg(\"Rating\").alias(\"AverageRating\"), count(\"*\").alias(\"BookCount\"))\n",
    "filtered_grouped_df = grouped_df.filter(col(\"BookCount\") > 1000)\n",
    "\n",
    "print(\"top-10 best year average rating\")\n",
    "filtered_grouped_df.orderBy(filtered_grouped_df.AverageRating.desc()) \\\n",
    "                   .show(10) \n",
    "\n",
    "print(\"top-10 worst year average rating\")\n",
    "filtered_grouped_df.orderBy(filtered_grouped_df.AverageRating) \\\n",
    "                   .show(10) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
